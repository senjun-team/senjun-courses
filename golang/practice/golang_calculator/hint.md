## Подход к выполнению практики

В этой подсказке приводятся указания по способу выполнения практики, описанному в разделе «Теория». Согласно этому способу вычисление алгебраического выражения состоит из трех этапов: токенизация, синтаксический анализ, вычисление выражения.

## Представление токенов

Каждый токен можно представить в виде структуры с двумя полями: `Lex` — значение токена; `T` — тип токена (число, скобка и т.д.). Тогда алгебраическое выражение представляется в виде списка токенов. В качестве типа для `Lex` может выступать, например, `string`. Для `T` — `int`. Удобно использовать псевдоним `Lexeme` — для `Lex` и `LexemeType` — для `T`.

Установить числовые значения для соответствующих типов можно следующим образом:

```golang
const (
	TokenNumber      = iota // число
	TokenOperator           // оператор
	TokenParanthesis        // скобка
)
```

Ключевое слова `iota` означает, что константе с именем `TokenNumber` присвоится число 0, `TokenOperator` — число 1, `TokenParanthesis` — число 2. Если бы мы продолжили создавать константы, числовой ряд бы так продолжился. 

Тогда строка с выражением `9.5-(1+3)` превращается в структуру со значениями:

```
{
    {
        "Lex": 9.5
        "T": "TokenNumber",
    },
    {
        "Lex": "-",
        "T": "TokenOperator"
    },
    {
        "Lex": "("
        "T": "TokenParanthesis"
    },
    {
        "Lex": 1
        "T": "TokenNumber",
    },
    {
        "Lex": "+"
        "T": "TokenOperator",
    },
    {
        "Lex": 3    
        "T": "TokenNumber",
        
    },
    {
        "Lex": ")"
        "T": "TokenParanthesis",
        
    }
}
```

Для того чтобы по исходному выражению получить список токенов, необходимо составить конечный автомат.

## Представление конечного автомата

КА для парсинга выражения на токены можно представить в виде хеш-таблицы хеш-таблиц.

Ключи словаря верхнего уровня — обозначения для классов (категорий) символов. Например, `"Digit"` для цифр, `"Point"` для точки, `"Parenthesis"` для скобок, `"Operator"` для математических операций. Значение по данному ключу — тоже хеш-таблица.

Ключи в этой вложенной хеш-таблице  — обозначения вариантов текущего состояния. А значения — структура из пары элементов: обозначения нового состояния и функции, которую требуется выполнить при переходе между состояниями. Как вы помните, в Go функции могут быть присвоены переменной (в том числе полю структуры).

Вот как может выглядеть КА в виде хеш-таблицы хеш-таблиц.

```go
// finite-state machine for the lexical analysis of the expression
type fsmT map[int]map[int]struct {
	state  int
	action func(*Command, rune, *lexemes.Token) *lexemes.Token
}

fsm := fsmT{
    Point: {
        NewToken: {
            NumberFractionalPart,
            startAccumulatingNumber,
        },
        NumberIntegerPart: {
            NumberFractionalPart,
            accumulateNumber,
        },
        NumberFractionalPart: {
            Error,
            nil,
        },
	},
    ...
}
```

Здесь `Point` — константа, обозначающая, что мы обрабатываем символ точки. `NewToken` — константа, обозначающая состояние обработки односимвольного токена, `startAccumulatingNumber` и `accumulateNumber` — функции, вызываемые *при переходе* к накоплению числа и *в процессе* накопления числа.

Допустим, конечный автомат представлен в виде словаря с именем `fsm` (finite-state machine). Тогда переключение между состояниями `curState` и `nextState` будет выглядеть так:

```go
data = fsm[curSymbol][curState]

nextState = data[0]
action = data[1]
```

Здесь `curSymbol` — класс обрабатываемого символа. Для его получения можно завести отдельную функцию, которая по символу возвращает обозначение его класса. 

## Реализация синтаксического анализа
Синтаксический анализ реализуется [методом рекурсивного спуска](https://ru.wikipedia.org/wiki/%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D1%80%D0%B5%D0%BA%D1%83%D1%80%D1%81%D0%B8%D0%B2%D0%BD%D0%BE%D0%B3%D0%BE_%D1%81%D0%BF%D1%83%D1%81%D0%BA%D0%B0). Для этого нужно завести функцию `viewLex`, в результате выполнения которой обновляются переменные очередного токена `tokenval` и следующего за ним — `lookahead`. Вначале очередной токен пустой, а следующий за ним — начальный. В конце очередной токен —  конечный, а следующий за ним — пустой. Функция `viewLex` работает с уже разобранным на токены выражением. Она нужна для удобной работы с токенами со стороны синтаксического анализатора. 

Также понадобится функция `match`, которая принимает токен. Если переданный токен равен токену `lookahead`, то вызывается функция `viewLex` и в качестве ошибки возвращается `nil`. Иначе — ошибка, отличная от `nil`. 

Для `expr`, `term` и `factor` грамматики также необходимо создать соответствующие функции. В начале разбора вызывается `viewLex`. Далее — с использованием `expr`, `term` и `factor` необходимо разобрать выражение в соответствии с грамматикой. По мере этого нужно построить AST. Для перехода на следующий токен внутри функций `expr`, `term` и `factor` используйте `match`.
